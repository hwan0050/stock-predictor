# ML Model

Python ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 ì´ìƒ
- pip ë˜ëŠ” conda
- (ì„ íƒ) GPU í™˜ê²½ (CUDA)

### Installation
```bash
cd ml-model
pip install -r requirements.txt
```

### ë°ì´í„° ìˆ˜ì§‘
```bash
python scripts/fetch_data.py --symbol 005930 --period 5y
```

### ëª¨ë¸ í•™ìŠµ
```bash
python train.py --symbol 005930 --model lstm
```

### ì˜ˆì¸¡ ì‹¤í–‰
```bash
python predict.py --symbol 005930 --days 7
```

---

## ğŸ“¦ Tech Stack

### Core Libraries
- **Python 3.8+** - í”„ë¡œê·¸ë˜ë° ì–¸ì–´
- **NumPy** - ìˆ˜ì¹˜ ê³„ì‚°
- **pandas** - ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„

### Machine Learning
- **scikit-learn** - ì „í†µì  ML ì•Œê³ ë¦¬ì¦˜
- **TensorFlow 2.x** - ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **Keras** - ê³ ìˆ˜ì¤€ ì‹ ê²½ë§ API
- **PyTorch** *(ì˜ˆì •)* - ëŒ€ì²´ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬

### Data Processing
- **yfinance** - Yahoo Finance ë°ì´í„° ìˆ˜ì§‘
- **pandas-ta** - ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
- **ta-lib** *(ì„ íƒ)* - ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„

### Visualization
- **matplotlib** - ê¸°ë³¸ ì‹œê°í™”
- **seaborn** - í†µê³„ ì‹œê°í™”
- **plotly** - ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸

### Model Management
- **MLflow** *(ì˜ˆì •)* - ëª¨ë¸ ì‹¤í—˜ ì¶”ì 
- **joblib** - ëª¨ë¸ ì§ë ¬í™”

### Development Tools
- **Jupyter Notebook** - ë°ì´í„° ë¶„ì„ ë° ì‹¤í—˜
- **pytest** - í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
- **black** - ì½”ë“œ í¬ë§·íŒ…

---

## ğŸ“ Project Structure
```
ml-model/
â”œâ”€â”€ data/                       # ë°ì´í„° ì €ì¥
â”‚   â”œâ”€â”€ raw/                   # ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â””â”€â”€ 005930.csv
â”‚   â”œâ”€â”€ processed/             # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”‚   â””â”€â”€ 005930_processed.csv
â”‚   â””â”€â”€ features/              # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê²°ê³¼
â”‚
â”œâ”€â”€ models/                     # ì €ì¥ëœ ëª¨ë¸
â”‚   â”œâ”€â”€ lstm_005930_v1.h5
â”‚   â”œâ”€â”€ scaler_005930.pkl
â”‚   â””â”€â”€ model_config.json
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_evaluation.ipynb
â”‚
â”œâ”€â”€ src/                        # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                  # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fetcher.py        # ë°ì´í„° ìˆ˜ì§‘
â”‚   â”‚   â”œâ”€â”€ processor.py      # ì „ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ features.py       # í”¼ì²˜ ìƒì„±
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # ëª¨ë¸ êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lstm.py           # LSTM ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ gru.py            # GRU ëª¨ë¸
â”‚   â”‚   â””â”€â”€ transformer.py    # Transformer ëª¨ë¸
â”‚   â”‚
â”‚   â”œâ”€â”€ training/              # í•™ìŠµ ê´€ë ¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py        # í•™ìŠµ ë¡œì§
â”‚   â”‚   â””â”€â”€ callbacks.py      # ì½œë°± í•¨ìˆ˜
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/            # í‰ê°€ ë©”íŠ¸ë¦­
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ visualizer.py     # ì‹œê°í™”
â”‚       â””â”€â”€ logger.py         # ë¡œê¹…
â”‚
â”œâ”€â”€ scripts/                    # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ fetch_data.py         # ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ preprocess.py         # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ evaluate.py           # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ tests/                      # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ config/                     # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ training_config.yaml
â”‚
â”œâ”€â”€ requirements.txt            # Python ì˜ì¡´ì„±
â”œâ”€â”€ setup.py                    # íŒ¨í‚¤ì§€ ì„¤ì •
â”œâ”€â”€ train.py                    # í•™ìŠµ ì§„ì…ì 
â”œâ”€â”€ predict.py                  # ì˜ˆì¸¡ ì§„ì…ì 
â””â”€â”€ README.md                   # ì´ ë¬¸ì„œ
```

---

## ğŸ¯ Features

### êµ¬í˜„ ì™„ë£Œ
- [ ] ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸
- [ ] ê¸°ë³¸ ì „ì²˜ë¦¬ ë¡œì§
- [ ] LSTM ëª¨ë¸ êµ¬í˜„

### ê°œë°œ ì¤‘
- [ ] íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê³ ë„í™”
- [ ] ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- [ ] ì„±ëŠ¥ í‰ê°€ ì§€í‘œ

### ì˜ˆì •
- [ ] Transformer ëª¨ë¸ êµ¬í˜„
- [ ] ì•™ìƒë¸” ëª¨ë¸
- [ ] AutoML í†µí•©
- [ ] ì‹¤ì‹œê°„ ì˜ˆì¸¡ API
- [ ] ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

---

## ğŸ§  Model Architecture

### LSTM (Long Short-Term Memory)
```python
model = Sequential([
    LSTM(128, return_sequences=True, input_shape=(sequence_length, features)),
    Dropout(0.2),
    LSTM(64, return_sequences=False),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)
])

model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae', 'mape']
)
```

### ì…ë ¥ íŠ¹ì„± (Features)

- **ê°€ê²© ë°ì´í„°**: Open, High, Low, Close, Volume
- **ê¸°ìˆ ì  ì§€í‘œ**:
  - ì´ë™í‰ê· : SMA(5, 20, 60), EMA(12, 26)
  - ëª¨ë©˜í…€: RSI, MACD, Stochastic
  - ë³¼ë¦°ì € ë°´ë“œ
  - ê±°ë˜ëŸ‰ ì§€í‘œ: OBV, Volume MA
- **ì‹œê°„ íŠ¹ì„±**: ìš”ì¼, ì›”, ë¶„ê¸°
- **ì™¸ë¶€ ìš”ì¸**: *(ì˜ˆì •)* í™˜ìœ¨, ê¸ˆë¦¬, ë‰´ìŠ¤ ê°ì„±

---

## ğŸ“Š Data Processing

### ë°ì´í„° ìˆ˜ì§‘
```python
from src.data.fetcher import StockDataFetcher

fetcher = StockDataFetcher()
data = fetcher.fetch(
    symbol='005930',
    start_date='2019-01-01',
    end_date='2024-01-01'
)
```

### ì „ì²˜ë¦¬
```python
from src.data.processor import DataProcessor

processor = DataProcessor()
processed_data = processor.process(
    data,
    normalize=True,
    handle_missing='interpolate',
    remove_outliers=True
)
```

### íŠ¹ì„± ìƒì„±
```python
from src.data.features import FeatureEngineering

fe = FeatureEngineering()
features = fe.create_features(
    processed_data,
    include_technical_indicators=True,
    window_sizes=[5, 20, 60]
)
```

---

## ğŸ“ Model Training

### ê¸°ë³¸ í•™ìŠµ
```bash
python train.py \
    --symbol 005930 \
    --model lstm \
    --epochs 100 \
    --batch-size 32 \
    --sequence-length 60
```

### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
```bash
python train.py \
    --symbol 005930 \
    --model lstm \
    --tune \
    --trials 50
```

### í•™ìŠµ ëª¨ë‹ˆí„°ë§
```python
from src.training.trainer import ModelTrainer

trainer = ModelTrainer(
    model=lstm_model,
    callbacks=[
        EarlyStopping(patience=10),
        ModelCheckpoint('best_model.h5'),
        TensorBoard(log_dir='./logs')
    ]
)

history = trainer.train(X_train, y_train, X_val, y_val)
```

---

## ğŸ”® Prediction

### ë‹¨ì¼ ì˜ˆì¸¡
```python
from src.models.lstm import LSTMPredictor

predictor = LSTMPredictor.load('models/lstm_005930_v1.h5')
prediction = predictor.predict(
    symbol='005930',
    days_ahead=7
)

print(f"7ì¼ í›„ ì˜ˆì¸¡ ê°€ê²©: {prediction['prices']}")
print(f"ì‹ ë¢°ë„: {prediction['confidence']}")
```

### ë°°ì¹˜ ì˜ˆì¸¡
```bash
python predict.py \
    --symbols 005930,035720,051910 \
    --days 7 \
    --output predictions.csv
```

---

## ğŸ“ˆ Evaluation Metrics

### íšŒê·€ ë©”íŠ¸ë¦­

- **MSE (Mean Squared Error)**: í‰ê·  ì œê³± ì˜¤ì°¨
- **RMSE (Root Mean Squared Error)**: í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨
- **MAE (Mean Absolute Error)**: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
- **MAPE (Mean Absolute Percentage Error)**: í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨
- **RÂ² Score**: ê²°ì • ê³„ìˆ˜

### ë°©í–¥ì„± ì •í™•ë„
```python
def direction_accuracy(y_true, y_pred):
    """
    ì‹¤ì œ ê°€ê²© ë³€ë™ ë°©í–¥ê³¼ ì˜ˆì¸¡ ë°©í–¥ì˜ ì¼ì¹˜ìœ¨
    """
    true_direction = np.sign(np.diff(y_true))
    pred_direction = np.sign(np.diff(y_pred))
    return np.mean(true_direction == pred_direction)
```

### í‰ê°€ ì‹¤í–‰
```bash
python scripts/evaluate.py \
    --model models/lstm_005930_v1.h5 \
    --test-data data/processed/test.csv
```

---

## ğŸ§ª Testing

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```bash
pytest tests/
```

### íŠ¹ì • í…ŒìŠ¤íŠ¸
```bash
pytest tests/test_models.py::test_lstm_prediction
```

### ì»¤ë²„ë¦¬ì§€
```bash
pytest --cov=src tests/
```

---

## ğŸ”§ Configuration

### model_config.yaml
```yaml
lstm:
  layers:
    - type: LSTM
      units: 128
      return_sequences: true
    - type: Dropout
      rate: 0.2
    - type: LSTM
      units: 64
    - type: Dense
      units: 32
      activation: relu
    - type: Dense
      units: 1
  
  compile:
    optimizer: adam
    loss: mse
    metrics: [mae, mape]

training:
  sequence_length: 60
  batch_size: 32
  epochs: 100
  validation_split: 0.2
```

---

## ğŸš§ Development Guidelines

### Code Style
- **PEP 8** ì¤€ìˆ˜
- **Type hints** ì‚¬ìš© ê¶Œì¥
- **Docstring**: NumPy ìŠ¤íƒ€ì¼

### ì˜ˆì‹œ
```python
def predict_price(
    symbol: str,
    days_ahead: int = 7,
    confidence_interval: float = 0.95
) -> Dict[str, Any]:
    """
    ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡
    
    Parameters
    ----------
    symbol : str
        ì¢…ëª© ì½”ë“œ
    days_ahead : int, default=7
        ì˜ˆì¸¡ ì¼ìˆ˜
    confidence_interval : float, default=0.95
        ì‹ ë¢° êµ¬ê°„
    
    Returns
    -------
    Dict[str, Any]
        ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    pass
```

### Commit Convention
```
feat(model): LSTM ëª¨ë¸ êµ¬í˜„
fix(data): ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜ ìˆ˜ì •
perf(training): í•™ìŠµ ì†ë„ ìµœì í™”
docs(readme): ì‚¬ìš© ì˜ˆì‹œ ì¶”ê°€
```

---

## ğŸ› Troubleshooting

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë©”ëª¨ë¦¬ ì„±ì¥ í—ˆìš©
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    tf.config.experimental.set_memory_growth(gpus[0], True)
```

### ë°ì´í„° ë¶€ì¡±
```bash
# ë” ê¸´ ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘
python scripts/fetch_data.py --symbol 005930 --period 10y
```

### ê³¼ì í•©
```python
# Dropout ë¹„ìœ¨ ì¦ê°€, Early Stopping ì‚¬ìš©
model.add(Dropout(0.3))  # 0.2 â†’ 0.3
```

---

## ğŸ“š Learning Resources

- [TensorFlow ê³µì‹ ë¬¸ì„œ](https://www.tensorflow.org/)
- [Keras ê°€ì´ë“œ](https://keras.io/guides/)
- [Time Series Forecasting](https://www.tensorflow.org/tutorials/structured_data/time_series)
- [pandas ë¬¸ì„œ](https://pandas.pydata.org/docs/)

---

## ğŸ¤ Contributing

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ [Issues](../../issues)ì— ë“±ë¡í•´ì£¼ì„¸ìš”.

ìì„¸í•œ ê¸°ì—¬ ë°©ë²•ì€ [CONTRIBUTING.md](../CONTRIBUTING.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ“ Contact

ë¬¸ì˜ì‚¬í•­: akma0050@naver.com